{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv(\n",
    "    './ml-100k/u.data', sep='\\t', names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create r_{ui}, our ratings matrix\n",
    "ratings = np.zeros((n_users, n_items))\n",
    "for row in df.itertuples():\n",
    "    ratings[row[1]-1, row[2]-1] = row[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into training and test sets. \n",
    "# Remove 10 ratings for each user \n",
    "# and assign them to the test set\n",
    "def train_test_split(ratings):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], \n",
    "                                        size=10, \n",
    "                                        replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test\n",
    "\n",
    "train, test = train_test_split(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_mse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import solve\n",
    "\n",
    "def alt_step(latent_vector, \n",
    "             fixed_vector,\n",
    "             ratings,\n",
    "             _lambda,\n",
    "             _type = 'user'):\n",
    "    \n",
    "    get_vec = lambda x: ratings[x, :]\n",
    "    if _type == 'item':\n",
    "        get_vec = lambda x: ratings[:, x].T\n",
    "    ATA = fixed_vector.T.dot(fixed_vector)\n",
    "    ATAlambdaI = ATA + np.eye(ATA.shape[0])*_lambda\n",
    "    for u_i in range(latent_vector.shape[0]):\n",
    "        latent_vector[u_i,:] = \\\n",
    "        solve(ATAlambdaI, get_vec(u_i).dot(fixed_vector))\n",
    "    return latent_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd(user_vector, item_vector, user_bias, item_bias, \n",
    "        global_bias, learning_rate, regularizer_factor, ratings, non_zero_row, non_zero_col):\n",
    "    rows = np.arange(len(non_zero_row))\n",
    "    np.random.shuffle(rows)\n",
    "    for i in rows:\n",
    "            user = non_zero_row[i]\n",
    "            item = non_zero_col[i]\n",
    "            prediction = global_bias + user_bias[user] + item_bias[item] + user_vector[user, :].dot(item_vector[item, :].T)\n",
    "            error = (ratings[user,item] - prediction) # error\n",
    "            \n",
    "            user_bias[user] += learning_rate * (error - regularizer_factor * user_bias[user])\n",
    "            item_bias[item] += learning_rate * (error - regularizer_factor * item_bias[item])\n",
    "            \n",
    "            user_vector[user, :] += learning_rate * (error * item_vector[item, :] - regularizer_factor * user_vector[user,:])\n",
    "            item_vector[item, :] += learning_rate * (error * user_vector[user, :] - regularizer_factor * item_vector[item, :])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(user_vector, item_vector, global_bias, user_bias, item_bias):\n",
    "    predictions = np.zeros((user_vector.shape[0], item_vector.shape[0]))\n",
    "    for user in range(user_vector.shape[0]):\n",
    "        for item in range(item_vector.shape[0]):\n",
    "            predictions[user, item] = global_bias + \\\n",
    "                user_bias[user] + item_bias[item] + user_vector[user, :].dot(item_vector[item, :].T)\n",
    "                \n",
    "    return predictions    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_user = train.shape[0]\n",
    "n_item = train.shape[1]\n",
    "n_factor = 40\n",
    "steps = 400\n",
    "user_vector = np.random.normal(scale=1./n_factor,size=(n_user, n_factor))\n",
    "item_vector = np.random.normal(scale=1./n_factor,size=(n_item, n_factor))\n",
    "user_bias = np.zeros(n_user)\n",
    "item_bias = np.zeros(n_item)\n",
    "global_bias = np.mean(train[np.where(train != 0)])\n",
    "non_zero_row, non_zero_col = train.nonzero()\n",
    "learning_rate = 0.001\n",
    "regularizer_factor = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "test mse  1.2755496757878833\n",
      "train mse  1.2663168859406702\n",
      "Step 10\n",
      "test mse  1.0183266436405871\n",
      "train mse  0.9175904020787433\n",
      "Step 20\n",
      "test mse  0.979125252487933\n",
      "train mse  0.8764130774587809\n",
      "Step 30\n",
      "test mse  0.9620323228727423\n",
      "train mse  0.8581931659885981\n",
      "Step 40\n",
      "test mse  0.9526522189518604\n",
      "train mse  0.8469674591719006\n",
      "Step 50\n",
      "test mse  0.9469877753796764\n",
      "train mse  0.8381361994846179\n",
      "Step 60\n",
      "test mse  0.9429873321406207\n",
      "train mse  0.8291620851839531\n",
      "Step 70\n",
      "test mse  0.9395559886101154\n",
      "train mse  0.8177177139119635\n",
      "Step 80\n",
      "test mse  0.9357901098833429\n",
      "train mse  0.8012193919745568\n",
      "Step 90\n",
      "test mse  0.9309036777865511\n",
      "train mse  0.7777222752478801\n",
      "Step 100\n",
      "test mse  0.9248312104326007\n",
      "train mse  0.7478985044123462\n",
      "Step 110\n",
      "test mse  0.9185644169774134\n",
      "train mse  0.7146020005379419\n",
      "Step 120\n",
      "test mse  0.9127538070000007\n",
      "train mse  0.6797245319407509\n",
      "Step 130\n",
      "test mse  0.9078782893136185\n",
      "train mse  0.6437598649808202\n",
      "Step 140\n",
      "test mse  0.904259613134203\n",
      "train mse  0.6071107855556286\n",
      "Step 150\n",
      "test mse  0.9019725110235512\n",
      "train mse  0.5704344682885792\n",
      "Step 160\n",
      "test mse  0.9012561597042945\n",
      "train mse  0.5344984651787626\n",
      "Step 170\n",
      "test mse  0.9021869179194336\n",
      "train mse  0.5000376472394225\n",
      "Step 180\n",
      "test mse  0.9046887043415801\n",
      "train mse  0.4676397680080227\n",
      "Step 190\n",
      "test mse  0.9086428177608218\n",
      "train mse  0.4376801621430481\n",
      "Step 200\n",
      "test mse  0.9138523436241535\n",
      "train mse  0.4103191731612723\n",
      "Step 210\n",
      "test mse  0.9201188458808627\n",
      "train mse  0.38554630666184\n",
      "Step 220\n",
      "test mse  0.9272741763476081\n",
      "train mse  0.36323462774459564\n",
      "Step 230\n",
      "test mse  0.9350598108274296\n",
      "train mse  0.34320149046865517\n",
      "Step 240\n",
      "test mse  0.943373150048874\n",
      "train mse  0.3252306354272356\n",
      "Step 250\n",
      "test mse  0.9520699255684641\n",
      "train mse  0.3091050001536826\n",
      "Step 260\n",
      "test mse  0.9609997317924319\n",
      "train mse  0.2946154849971732\n",
      "Step 270\n",
      "test mse  0.9700834836566389\n",
      "train mse  0.281570013676864\n",
      "Step 280\n",
      "test mse  0.9791947654510472\n",
      "train mse  0.2697949688472046\n",
      "Step 290\n",
      "test mse  0.9884164622078345\n",
      "train mse  0.2591374524607778\n",
      "Step 300\n",
      "test mse  0.9975819926447413\n",
      "train mse  0.24946300787731443\n",
      "Step 310\n",
      "test mse  1.0066751323701832\n",
      "train mse  0.2406550851128806\n",
      "Step 320\n",
      "test mse  1.0157883165572652\n",
      "train mse  0.23261289149192085\n",
      "Step 330\n",
      "test mse  1.0247284856144643\n",
      "train mse  0.22524875125563124\n",
      "Step 340\n",
      "test mse  1.033570034253429\n",
      "train mse  0.2184871814141602\n",
      "Step 350\n",
      "test mse  1.0423047941350752\n",
      "train mse  0.21226296233001943\n",
      "Step 360\n",
      "test mse  1.0509054521521541\n",
      "train mse  0.2065194240234564\n",
      "Step 370\n",
      "test mse  1.0593564372523252\n",
      "train mse  0.20120673878150888\n",
      "Step 380\n",
      "test mse  1.067752259860356\n",
      "train mse  0.19628213427802835\n",
      "Step 390\n",
      "test mse  1.075968702911231\n",
      "train mse  0.19170744730469017\n"
     ]
    }
   ],
   "source": [
    "for i in range(steps):\n",
    "    if(i%10==0):\n",
    "        print(\"Step %d\" %  i)\n",
    "        predictions = inference(user_vector, item_vector, global_bias, user_bias, item_bias) \n",
    "        print (\"test mse \", get_mse(predictions, test))\n",
    "        print (\"train mse \", get_mse(predictions, train))\n",
    "    sgd(user_vector, item_vector, user_bias, item_bias, \n",
    "        global_bias, learning_rate, regularizer_factor, train, non_zero_row, non_zero_col)\n",
    "#     user_vector = alt_step(user_vector, item_vector, train, usr_lambda)\n",
    "#     item_vector = alt_step(item_vector, user_vector, train, item_lambda, 'item')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
