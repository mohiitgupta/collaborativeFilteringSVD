{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formula\n",
    "<div class=hidden>\n",
    "### Estimated rating for svd++  \n",
    "$$\\hat{r}_{ui}=\\mu+b_i+b_u+q_i^T\\left(p_u+|N(u)|^{\\frac{1}{2}}\\sum_{j\\in N(u)}y_j\\right)$$ \n",
    "\n",
    "### Loss function (MSE):\n",
    "$$ \\underset{b_*,\\  q_*,\\  p_*,\\  y_*}{min}\\sum_{(u,i)\\in \\kappa}\\left[ r_{ui}-\\mu - b_u - b_i -q_i^T\\left(p_u+|N(u)|^{\\frac{1}{2}}\\sum_{j\\in N(u)}y_j\\right)\\right]^2 + \\lambda\\left[b_u^2+b_i^2+\\|q_i\\|^2+\\|p_u\\|^2+\\sum_{j\\in N(u)}\\|y_j\\|^2\\right]$$\n",
    "\n",
    "Variable/Knowns:\n",
    "* $r_{u,i}$: user u's rating on item i\n",
    "* $u$: user\n",
    "* $i$: item\n",
    "* $\\kappa$: known ratings\n",
    "\n",
    "Hyperparameter:\n",
    "* $k$: number of hidden features\n",
    "* $\\lambda$: regularization\n",
    "* $\\alpha$: learning rate\n",
    "\n",
    "\n",
    "Parameters to learn:\n",
    "* $b_i$ : [n_item, k]\n",
    "* $b_u$ : [n_user, k]\n",
    "* $q_i$ : []\n",
    "* $p_u$ : []\n",
    "* $y_i$ : []\n",
    "\n",
    "\n",
    "Constants:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and split data, create our own MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv(\n",
    "    './ml-100k/u.data', sep='\\t', names=names)\n",
    "\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "\n",
    "# Create r_{ui}, our ratings matrix\n",
    "ratings = np.zeros((n_users, n_items))\n",
    "for row in df.itertuples():\n",
    "    ratings[row[1]-1, row[2]-1] = row[3]\n",
    "\n",
    "# Split into training and test sets. \n",
    "# Remove 10 ratings for each user \n",
    "# and assign them to the test set\n",
    "def train_test_split(ratings):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], \n",
    "                                        size=10, \n",
    "                                        replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test\n",
    "\n",
    "train, test = train_test_split(ratings)\n",
    "indicating_mat = np.vectorize(lambda x: 0 if x==0 else 1)(train)\n",
    "mask = indicating_mat == 1\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_mse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9430,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.nonzero()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90570,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.nonzero()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.nonzero()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_user, n_item = train.shape\n",
    "\n",
    "# Hyperparameter:\n",
    "k = 40\n",
    "steps = 10\n",
    "lrate = 0.001\n",
    "_lambda = 0.001\n",
    "\n",
    "# Parameters:\n",
    "b_u = np.zeros(n_user)\n",
    "b_i = np.zeros(n_item)\n",
    "\n",
    "#q_i\n",
    "q_i = np.random.normal(scale=1./k, size=(n_item, k))\n",
    "#P_u\n",
    "p_u = np.random.normal(scale=1./k, size=(n_user, k))\n",
    "#y_i\n",
    "y_j = np.random.normal(scale=1./k, size=(n_item, k))\n",
    "\n",
    "global_bias = np.mean(train[np.where(train != 0)])\n",
    "\n",
    "non_zeros = train.nonzero()\n",
    "\n",
    "# This is equivalent of taking the length and doing the square root.\n",
    "# N = np.power(indicating_mat.sum(1), -0.5)\n",
    "N = 1./np.linalg.norm(indicating_mat, axis = 1)\n",
    "\n",
    "def predict_one(u, i, b_i, b_u, q_i, q_u, y_j):\n",
    "    return global_bias + b_i[i] + b_u[u] + \\\n",
    "    q_i[i,:].T.dot(p_u[u, :] + N[u] * y_j[mask[u,:], :].sum(axis=0))\n",
    "\n",
    "def svdpp_step():\n",
    "    rows = np.random.permutation(len(non_zeros[0]))\n",
    "    for i in rows:\n",
    "        user = non_zeros[0][i]\n",
    "        item = non_zeros[1][i]\n",
    "        pred = predict_one(user, item, b_i, b_u, q_i, p_u, y_j)\n",
    "        ## Watch out to turn learning rate separately, this needs to be calculate separately\n",
    "        error = train[user][item] - pred\n",
    "        \n",
    "        b_u[user] += lrate*(error - _lambda * b_u[user])\n",
    "        b_i[item] += lrate*(error - _lambda * b_i[item])\n",
    "        \n",
    "        ## Update for q_i (item vector)\n",
    "        q_i[item, :] += lrate * (error * (p_u[user,:] + N[user]* y_j[mask[user, :], :].sum(axis=0)) - _lambda * q_i[item, :])\n",
    "        \n",
    "        # Update for p_u (user vector)\n",
    "        p_u[user, :] += lrate * (error * q_i[item, :] - _lambda * p_u[user,:])\n",
    "        \n",
    "        # Update for each y_j \n",
    "        temp = error * N[user] * q_i[item, :]\n",
    "        j = indicating_mat[user,:].nonzero()\n",
    "#         for j in indicating_mat[user,:].nonzero()[0]:\n",
    "        y_j[j,:] += lrate * (temp - _lambda * y_j[j,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "def predict():\n",
    "    predictions = np.zeros([n_user, n_item])\n",
    "    for user in range(n_users):\n",
    "        for item in range(n_items):\n",
    "            predictions[user, item] = predict_one(user, item, b_i, \\\n",
    "                        b_u, q_i, p_u, y_j)\n",
    "    data.append([get_mse(predictions, train),get_mse(predictions, test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for i in range(400):\n",
    "    print(i)\n",
    "    svdpp_step()\n",
    "    if i%10 == 0:\n",
    "        predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf = pd.DataFrame(data)\n",
    "dtf.to_csv(\"svd++Result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.932733067743351"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_mse(predictions, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8126666901524443"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_mse(predictions, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
